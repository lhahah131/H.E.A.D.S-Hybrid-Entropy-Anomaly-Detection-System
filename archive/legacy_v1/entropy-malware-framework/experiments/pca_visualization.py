
import os
import pandas as pd
import matplotlib.pyplot as plt

from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA

# ======================
# PATH CONFIGURATION
# ======================
# Get the directory where this script is located
script_dir = os.path.dirname(os.path.abspath(__file__))
# The project root is one level up
project_root = os.path.dirname(script_dir)
# Define the absolute path to the CSV file
csv_path = os.path.join(project_root, "features", "master_features.csv")

# ======================
# LOAD DATASET
# ======================
try:
    df = pd.read_csv(csv_path)
    print(f"Successfully loaded dataset from: {csv_path}")
except FileNotFoundError:
    print(f"Error: Could not find file at {csv_path}")
    print("Please run this script from the project root or ensure the file exists.")
    exit(1)

# Separate file_id
file_ids = df["file_id"]
X = df.drop(columns=["file_id"])

# Scaling
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# PCA to 2D
pca = PCA(n_components=2)
X_pca = pca.fit_transform(X_scaled)

# Plot scatter points
plt.figure(figsize=(10, 8))
plt.scatter(X_pca[:, 0], X_pca[:, 1], alpha=0.7)

# Annotate points
for i, file_id in enumerate(file_ids):
    plt.annotate(file_id, (X_pca[i, 0], X_pca[i, 1]), fontsize=8, alpha=0.8)

plt.title("PCA Visualization - Entropy Feature Space")
plt.xlabel(f"Principal Component 1 ({pca.explained_variance_ratio_[0]:.2f})")
plt.ylabel(f"Principal Component 2 ({pca.explained_variance_ratio_[1]:.2f})")
plt.grid(True, linestyle='--', alpha=0.6)
plt.tight_layout()
plt.show()